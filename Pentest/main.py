from concurrent.futures import ThreadPoolExecutor
import httpx
import urllib3
import threading
import io

extension_name = ['.bak', '.7z', '.nr', '.swp', '.tar.gz', '.zip', '.jsp']

write_file_lock = threading.Lock()
MAX_THREADS = 64

headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
}
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def url_generator(domain: str, filepath: str):
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            word = line.strip().strip('/')
            yield f'{domain}/{word}'
            if '.' not in word:
                for ex in extension_name:
                    yield f'{domain}/{word}{ex}'


def url_test(url: str, out: io.TextIOWrapper):
    try:
        resp = httpx.get(url, headers=headers, verify=False)
        if resp.status_code == 200:
            write_file_lock.acquire()
            print(f"[{resp.status_code}]==>{url}")
            out.write(url + "\n")
            write_file_lock.release()
        return 0
    except Exception as e:
        print(f"[Error] {e}")
        return -1


def run_task_threads(domain: str, filepath: str, resultfile: str):
    url_gen = url_generator(domain, filepath)
    with open(resultfile, 'w', encoding='utf-8') as fp:
        with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
            while True:
                try:
                    url = next(url_gen)
                    executor.submit(url_test, url, fp)
                except StopIteration as si:
                    break


run_task_threads("http://testfire.net", "./dic.txt", "./result.txt")
